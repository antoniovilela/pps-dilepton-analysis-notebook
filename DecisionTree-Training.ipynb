{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "#import mplhep\n",
    "from matplotlib.colors import LogNorm\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proton_selection = \"SingleRP\"\n",
    "proton_selection = \"MultiRP\"\n",
    "\n",
    "train_model = True\n",
    "run_grid_search = True\n",
    "save_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data( fileNames ):\n",
    "    df_list = []\n",
    "    df_counts_list = []\n",
    "\n",
    "    for file_ in fileNames:\n",
    "        print ( file_ )\n",
    "        with h5py.File( file_, 'r' ) as f:\n",
    "            print ( list(f.keys()) )\n",
    "            dset = f['protons']\n",
    "            print ( dset.shape )\n",
    "            print ( dset[:,:] )\n",
    "\n",
    "            dset_columns = f['columns']\n",
    "            print ( dset_columns.shape )\n",
    "            columns = list( dset_columns )\n",
    "            print ( columns )\n",
    "            columns_str = [ item.decode(\"utf-8\") for item in columns ]\n",
    "            print ( columns_str )\n",
    "\n",
    "            dset_selections = f['selections']\n",
    "            selections_ = [ item.decode(\"utf-8\") for item in dset_selections ]\n",
    "            print ( selections_ )\n",
    "\n",
    "            dset_counts = f['event_counts']\n",
    "            df_counts_list.append( pd.Series( dset_counts, index=selections_ ) )\n",
    "            print ( df_counts_list[-1] )\n",
    "\n",
    "            chunk_size = 1000000\n",
    "            entries = dset.shape[0]\n",
    "            start_ = list( range( 0, entries, chunk_size ) )\n",
    "            stop_ = start_[1:]\n",
    "            stop_.append( entries )\n",
    "            print ( start_ )\n",
    "            print ( stop_ )\n",
    "            for idx in range( len( start_ ) ):\n",
    "                print ( start_[idx], stop_[idx] )\n",
    "                #print ( dset[ start_[idx] : stop_[idx] ] )\n",
    "                df_ = pd.DataFrame( dset[ start_[idx] : stop_[idx] ], columns=columns_str )\n",
    "                df_ = df_[ ['Run', 'LumiSection', 'EventNum', 'CrossingAngle', \n",
    "                            'MultiRP', 'Arm', 'RPId1', 'RPId2', 'TrackX1', 'TrackY1', 'TrackX2', 'TrackY2',\n",
    "                            'Xi', 'T', 'ThX', 'ThY', 'Time',\n",
    "                            'Muon0Pt', 'Muon1Pt', 'InvMass', 'ExtraPfCands', 'Acopl', 'XiMuMuPlus', 'XiMuMuMinus'] ].astype( { \"Run\": \"int64\", \"LumiSection\": \"int64\", \"EventNum\": \"int64\", \"MultiRP\": \"int32\", \"Arm\": \"int32\", \"RPId1\": \"int32\", \"RPId2\": \"int32\", \"ExtraPfCands\": \"int32\" } )\n",
    "                df_list.append( df_ )\n",
    "                print ( df_list[-1].head() )\n",
    "                print ( len( df_list[-1] ) )\n",
    "\n",
    "    df_counts = df_counts_list[0]\n",
    "    for idx in range( 1, len( df_counts_list ) ):\n",
    "        df_counts = df_counts.add( df_counts_list[idx] )\n",
    "    print ( df_counts )\n",
    "\n",
    "    df = pd.concat( df_list )\n",
    "    print ( df )\n",
    "    \n",
    "    return ( df_counts, df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data( df ):\n",
    "    msk = ( df[\"InvMass\"] >= 110. )\n",
    "\n",
    "    msk1 = None\n",
    "    msk2 = None\n",
    "    if proton_selection == \"SingleRP\":\n",
    "        # Single-RP in pixel stations\n",
    "        msk1_arm = ( df[\"RPId1\"] == 23 )\n",
    "        msk2_arm = ( df[\"RPId1\"] == 123 )\n",
    "        df[ \"XiMuMu\" ] = np.nan\n",
    "        df[ \"XiMuMu\" ].where( ~msk1_arm, df[ \"XiMuMuPlus\" ], inplace=True )\n",
    "        df[ \"XiMuMu\" ].where( ~msk2_arm, df[ \"XiMuMuMinus\" ], inplace=True )\n",
    "        #df_signal[ \"XiMuMu\" ][ msk2_arm ] = df_signal[ \"XiMuMuMinus\" ] \n",
    "        msk1 = msk & ( df[\"MultiRP\"] == 0) & msk1_arm\n",
    "        msk2 = msk & ( df[\"MultiRP\"] == 0) & msk2_arm\n",
    "    elif proton_selection == \"MultiRP\":\n",
    "        # Multi-RP\n",
    "        msk1_arm = ( df[\"Arm\"] == 0 )\n",
    "        msk2_arm = ( df[\"Arm\"] == 1 )\n",
    "        df[ \"XiMuMu\" ] = np.nan\n",
    "        df[ \"XiMuMu\" ].where( ~msk1_arm, df[ \"XiMuMuPlus\" ], inplace=True )\n",
    "        df[ \"XiMuMu\" ].where( ~msk2_arm, df[ \"XiMuMuMinus\" ], inplace=True )\n",
    "        msk1 = msk & ( df[\"MultiRP\"] == 1 ) & msk1_arm\n",
    "        msk2 = msk & ( df[\"MultiRP\"] == 1 ) & msk2_arm\n",
    "\n",
    "    df = df[ msk1 | msk2 ]\n",
    "    return ( df )    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNames_signal = [\n",
    "    'output/output-MC2017-Elastic-Non3+3-PreSel.h5'\n",
    "    #'output-MC2017-SingleDissociation-PreSel.h5'\n",
    "]\n",
    "\n",
    "df_counts_signal, df_signal = get_data( fileNames_signal )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_signal = process_data( df_signal )\n",
    "df_signal[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_factor = 20\n",
    "\n",
    "fileNames_bkg = [\n",
    "    'output/output-UL2017B-PreSel-Rnd-Res20.h5',\n",
    "    'output/output-UL2017C1-PreSel-Rnd-Res20.h5',\n",
    "    'output/output-UL2017E-PreSel-Rnd-Res20.h5',\n",
    "    'output/output-UL2017F1-PreSel-Rnd-Res20.h5'\n",
    "]\n",
    "\n",
    "df_counts_bkg, df_bkg = get_data( fileNames_bkg )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bkg = process_data( df_bkg )\n",
    "df_bkg[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sig = df_signal[ ['Xi', 'Muon0Pt', 'Muon1Pt', 'InvMass', 'ExtraPfCands', 'Acopl', 'XiMuMu'] ]\n",
    "print ( X_sig[:20] )\n",
    "\n",
    "X_bkg = df_bkg[ ['Xi', 'Muon0Pt', 'Muon1Pt', 'InvMass', 'ExtraPfCands', 'Acopl', 'XiMuMu'] ]\n",
    "print ( X_bkg[:20] )\n",
    "\n",
    "y_sig = np.ones( len(X_sig) )\n",
    "y_bkg = np.zeros( len(X_bkg) )\n",
    "\n",
    "X = pd.concat( [X_sig, X_bkg] ) \n",
    "y = np.concatenate( [y_sig, y_bkg] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, shuffle=True, random_state=42 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model (example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "    \n",
    "ada_clf = AdaBoostClassifier(\n",
    "            DecisionTreeClassifier( max_depth=4 ),\n",
    "            n_estimators = 200,\n",
    "            algorithm=\"SAMME.R\",\n",
    "            learning_rate = 0.5)\n",
    "ada_clf.fit( X_train, y_train )\n",
    "model = ada_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_proba = model.predict_proba( X_test )[:,1]\n",
    "print ( y_test_proba )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize=(10,10) )\n",
    "plt.hist( y_test_proba[ y_test == 0 ], histtype='step', color='orange', bins=60, range=(0.,1.) )\n",
    "plt.hist( y_test_proba[ y_test == 1 ], histtype='step', color='skyblue', bins=60, range=(0.,1.) )\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid_search = None\n",
    "\n",
    "if train_model and run_grid_search:\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    #from sklearn.model_selection import GridSearchCV\n",
    "    from scipy.stats import uniform\n",
    "\n",
    "    param_distribs = {\n",
    "        \"base_estimator__max_depth\": np.arange(2,10),\n",
    "        \"n_estimators\": 100*np.arange(1,6),\n",
    "        \"learning_rate\": uniform()\n",
    "        }\n",
    "    #param_grid = [\n",
    "    #    { \"max_depth\": np.arange(2,10),\n",
    "    #      \"n_estimators\": 100 * np.arange(1,6),\n",
    "    #      \"learning_rate\": 0.1 * np.arange(5,11) }\n",
    "    #    ]\n",
    "\n",
    "    grid_search = RandomizedSearchCV(\n",
    "        AdaBoostClassifier(\n",
    "            DecisionTreeClassifier(),\n",
    "            algorithm=\"SAMME.R\"\n",
    "            ),\n",
    "        param_distribs,\n",
    "        n_iter=10, cv=3, verbose=20, n_jobs=-1, random_state=42\n",
    "        )\n",
    "    grid_search.fit( X_train, y_train )\n",
    "\n",
    "    print ( grid_search.best_params_ )\n",
    "    print ( grid_search.best_score_ )\n",
    "    print ( grid_search.cv_results_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = None\n",
    "\n",
    "if train_model:\n",
    "    if run_grid_search: \n",
    "        print ( grid_search.best_estimator_)\n",
    "        model_final = grid_search.best_estimator_.model\n",
    "    else\n",
    "        model_final = AdaBoostClassifier(\n",
    "            DecisionTreeClassifier( max_depth=4 ),\n",
    "            n_estimators = 200,\n",
    "            algorithm=\"SAMME.R\",\n",
    "            learning_rate = 0.5)\n",
    "        model_final.fit( X_train, y_train )\n",
    "else:\n",
    "    model_final = load( \"model/ada_clf.joblib\" )\n",
    "    \n",
    "print ( model_final )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_proba = model_final.predict_proba( X_test )[:,1]\n",
    "print ( y_test_proba )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize=(10,10) )\n",
    "plt.hist( y_test_proba[ y_test == 0 ], histtype='step', color='orange', bins=60, range=(0.,1.) )\n",
    "plt.hist( y_test_proba[ y_test == 1 ], histtype='step', color='skyblue', bins=60, range=(0.,1.) )\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_cut = 0.50\n",
    "\n",
    "y_test_pred = ( y_test_proba >= prob_cut ).astype( \"int32\" )\n",
    "print ( y_test_pred )\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print ( accuracy_score( y_test, y_test_pred ) )\n",
    "print ( accuracy_score( y_test[ y_test == 1 ], y_test_pred[ y_test == 1 ] ) )\n",
    "print ( accuracy_score( y_test[ y_test == 0 ], y_test_pred[ y_test == 0 ] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model and save_model:\n",
    "    dump( model_final, \"model/ada_clf.joblib\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform\n",
    "np.info(uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "np.info( AdaBoostClassifier )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#np.info( RandomizedSearchCV )\n",
    "print ( RandomizedSearchCV(AdaBoostClassifier(\n",
    "            DecisionTreeClassifier( random_state=42 ),\n",
    "            algorithm=\"SAMME.R\"\n",
    "            ),\n",
    "            param_distribs)\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
